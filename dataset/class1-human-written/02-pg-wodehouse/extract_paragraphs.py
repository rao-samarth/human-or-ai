# This file is generated by Claude Sonnet 4.5
# It is used for random paragraph extraction from P. G. Wodehouse books.

"""
Script to extract paragraphs from P. G. Wodehouse books.

This script:
1. Identifies books with at least 20 paragraphs between 100-250 words
2. Randomly selects 25 such books
3. Extracts 20 random qualifying paragraphs from each book
4. Saves each paragraph to a separate file with naming: booknumber_bookname_paragraphnumber.txt
"""

import os
import re
import random
import csv
from pathlib import Path


def count_words(text):
    """Count words in a text string."""
    return len(text.split())


def extract_paragraphs_from_file(filepath):
    """
    Extract all paragraphs from a file.
    
    Returns:
        List of paragraphs (strings)
    """
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Split by double newlines to get paragraphs
    paragraphs = re.split(r'\n\s*\n', content)
    
    # Clean up paragraphs - strip whitespace and filter out empty ones
    paragraphs = [p.strip() for p in paragraphs if p.strip()]
    
    return paragraphs


def filter_paragraphs_by_word_count(paragraphs, min_words=100, max_words=250):
    """
    Filter paragraphs that have word count between min_words and max_words.
    
    Returns:
        List of tuples: (paragraph_index, paragraph_text)
    """
    qualifying_paragraphs = []
    
    for idx, para in enumerate(paragraphs):
        word_count = count_words(para)
        if min_words <= word_count <= max_words:
            qualifying_paragraphs.append((idx, para))
    
    return qualifying_paragraphs


def load_book_info(csv_path):
    """
    Load book information from admin.csv.
    
    Returns:
        Dictionary mapping book filename to paragraph count info
    """
    book_info = {}
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            book_name = row['Book']
            qualifying_count = int(row['Paragraphs (100-250 words)'])
            book_info[book_name] = qualifying_count
    
    return book_info


def extract_book_number_and_name(filename):
    """
    Extract book number and name from filename.
    
    Example: '003_ASH_01_Scandal_In_Bohemia.txt' -> ('003', 'ASH_01_Scandal_In_Bohemia')
    """
    # Remove .txt extension
    name_without_ext = filename.replace('.txt', '')
    
    # Split by first underscore to get book number
    parts = name_without_ext.split('_', 1)
    
    if len(parts) == 2:
        book_number = parts[0]
        book_name = parts[1]
    else:
        # Fallback if format is different
        book_number = name_without_ext[:3]
        book_name = name_without_ext[4:] if len(name_without_ext) > 4 else name_without_ext
    
    return book_number, book_name


def main():
    # Configuration
    script_dir = Path(__file__).parent
    csv_path = script_dir / 'admin.csv'
    output_dir = script_dir / 'extracted_paragraphs'
    
    min_qualifying_paragraphs = 20
    num_books_to_select = 25
    num_paragraphs_per_book = 20
    
    # Create output directory
    output_dir.mkdir(exist_ok=True)
    
    # Delete existing .txt files in the output directory
    print("=" * 80)
    print("ARTHUR CONAN DOYLE PARAGRAPH EXTRACTION")
    print("=" * 80)
    
    print("\n[0] Cleaning output directory...")
    existing_txt_files = list(output_dir.glob('*.txt'))
    if existing_txt_files:
        print(f"    Found {len(existing_txt_files)} existing .txt files")
        for txt_file in existing_txt_files:
            txt_file.unlink()
            print(f"      Deleted: {txt_file.name}")
        print(f"    Deleted {len(existing_txt_files)} files")
    else:
        print("    No existing .txt files found")
    
    # Load book information
    print("\n[1] Loading book information from admin.csv...")
    book_info = load_book_info(csv_path)
    print(f"    Loaded information for {len(book_info)} books")
    
    # Filter books with at least 20 qualifying paragraphs
    print(f"\n[2] Filtering books with at least {min_qualifying_paragraphs} qualifying paragraphs...")
    eligible_books = {
        book: count for book, count in book_info.items()
        if count >= min_qualifying_paragraphs
    }
    print(f"    Found {len(eligible_books)} eligible books")
    
    if len(eligible_books) < num_books_to_select:
        print(f"\n    WARNING: Only {len(eligible_books)} eligible books found, but {num_books_to_select} requested.")
        print(f"    Will process all {len(eligible_books)} available books.")
        num_books_to_select = len(eligible_books)
    
    # Randomly select 25 books
    print(f"\n[3] Randomly selecting {num_books_to_select} books...")
    selected_books = random.sample(list(eligible_books.keys()), num_books_to_select)
    selected_books.sort()  # Sort for consistent output
    
    print(f"    Selected books:")
    for book in selected_books:
        print(f"      - {book} ({eligible_books[book]} qualifying paragraphs)")
    
    # Process each selected book
    print(f"\n[4] Extracting {num_paragraphs_per_book} paragraphs from each book...")
    
    total_files_created = 0
    extraction_log = []
    
    for book_filename in selected_books:
        book_path = script_dir / book_filename
        
        if not book_path.exists():
            print(f"\n    ERROR: Book file not found: {book_filename}")
            continue
        
        # Extract book number and name
        book_number, book_name = extract_book_number_and_name(book_filename)
        
        print(f"\n    Processing: {book_filename}")
        print(f"      Book number: {book_number}")
        print(f"      Book name: {book_name}")
        
        # Extract all paragraphs
        all_paragraphs = extract_paragraphs_from_file(book_path)
        print(f"      Total paragraphs in file: {len(all_paragraphs)}")
        
        # Filter qualifying paragraphs
        qualifying_paragraphs = filter_paragraphs_by_word_count(all_paragraphs)
        print(f"      Qualifying paragraphs (100-250 words): {len(qualifying_paragraphs)}")
        
        if len(qualifying_paragraphs) < num_paragraphs_per_book:
            print(f"      WARNING: Only {len(qualifying_paragraphs)} qualifying paragraphs found, need {num_paragraphs_per_book}")
            print(f"      Will extract all {len(qualifying_paragraphs)} available paragraphs")
            selected_paragraphs = qualifying_paragraphs
        else:
            # Randomly select 20 paragraphs
            selected_paragraphs = random.sample(qualifying_paragraphs, num_paragraphs_per_book)
        
        # Sort by original index to maintain order
        selected_paragraphs.sort(key=lambda x: x[0])
        
        # Save each paragraph to a file
        for para_num, (original_idx, para_text) in enumerate(selected_paragraphs, 1):
            # Filename format: booknumber_bookname_paragraphnumber.txt
            output_filename = f"{book_number}_{book_name}_{para_num:02d}.txt"
            output_path = output_dir / output_filename
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(para_text)
            
            total_files_created += 1
            extraction_log.append({
                'book_filename': book_filename,
                'book_number': book_number,
                'book_name': book_name,
                'paragraph_number': para_num,
                'original_paragraph_index': original_idx,
                'word_count': count_words(para_text),
                'output_filename': output_filename
            })
        
        print(f"      Created {len(selected_paragraphs)} files")
    
    # Save extraction log
    log_path = output_dir / 'extraction_log.csv'
    print(f"\n[5] Saving extraction log to {log_path.name}...")
    
    with open(log_path, 'w', encoding='utf-8', newline='') as f:
        fieldnames = ['book_filename', 'book_number', 'book_name', 'paragraph_number', 
                      'original_paragraph_index', 'word_count', 'output_filename']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(extraction_log)
    
    print(f"    Log saved with {len(extraction_log)} entries")
    
    # Summary
    print("\n" + "=" * 80)
    print("EXTRACTION COMPLETE")
    print("=" * 80)
    print(f"Books processed: {len(selected_books)}")
    print(f"Total files created: {total_files_created}")
    print(f"Output directory: {output_dir}")
    print(f"Extraction log: {log_path}")
    print("=" * 80)


if __name__ == "__main__":
    # Set random seed for reproducibility (optional - remove if you want different results each time)
    # random.seed(42)
    
    main()
