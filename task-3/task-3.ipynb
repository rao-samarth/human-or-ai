{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3d87604",
   "metadata": {},
   "source": [
    "# Task-3\n",
    "\n",
    "Here, we want to know why the model thinks a text is AI generated.  \n",
    "\n",
    "We are required to use either [SHAP](https://shap.readthedocs.io/en/latest/) or [Captum](https://captum.ai/) for this task. I have decided to use SHAP because:\n",
    "1. It seems to have nicer visualisations\n",
    "2. Captum seems to be primarily for PyTorch.\n",
    "\n",
    "> highlight the words in an **\"Imposter\" paragraph** that most strongly signaled \"AI\" to your Tier C model.\n",
    "\n",
    "This is a bit of a problem. I do not have 3 such paragraphs as recommended. I only have 1 paragraph which was class-1, but mistaken to be class-3. \n",
    "\n",
    "I instead have decided to use SHAP to analyse the ones classified with the least confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samarth/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mshap\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/shap/__init__.py:48\u001b[39m\n\u001b[32m     46\u001b[39m     have_matplotlib = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_matplotlib:\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plots\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bar_legacy \u001b[38;5;28;01mas\u001b[39;00m bar_plot\n\u001b[32m     50\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplots\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_beeswarm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary_legacy \u001b[38;5;28;01mas\u001b[39;00m summary_plot\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/shap/plots/__init__.py:8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmatplotlib is not installed so plotting is not available! Run `pip install matplotlib` to fix this.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m     )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bar\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_beeswarm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m beeswarm\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_benchmark\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m benchmark\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/shap/plots/_bar.py:4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/matplotlib/pyplot.py:69\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _docstring\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     68\u001b[39m     FigureCanvasBase, FigureManagerBase, MouseButton)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfigure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Figure, FigureBase, figaspect\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgridspec\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rcsetup, rcParamsDefault, rcParamsOrig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/matplotlib/figure.py:40\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmpl\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _blocking_input, backend_bases, _docstring, projections\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     42\u001b[39m     Artist, allow_rasterization, _finalize_rasterization)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     44\u001b[39m     DrawEvent, FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/matplotlib/projections/__init__.py:55\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mNon-separable transforms that map from data space to screen space.\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m \u001b[33;03m`matplotlib.projections.polar` may also be of interest.\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m axes, _docstring\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AitoffAxes, HammerAxes, LambertAxes, MollweideAxes\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpolar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PolarAxes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/matplotlib/axes/__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _base\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_axes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Axes\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Backcompat.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/precog-task/human-or-ai/venv2/lib/python3.12/site-packages/matplotlib/axes/_base.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, _docstring, offsetbox\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01martist\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmartist\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maxis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmaxis\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcbook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _OrderedSet, _check_1d, index_of\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmcoll\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1360\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1331\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:935\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:991\u001b[39m, in \u001b[36mexec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:1124\u001b[39m, in \u001b[36mget_code\u001b[39m\u001b[34m(self, fullname)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:753\u001b[39m, in \u001b[36m_compile_bytecode\u001b[39m\u001b[34m(data, name, bytecode_path, source_path)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import shap\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL_PATH = \"tier_c_final_model\"\n",
    "DATASET_DIR = Path('../dataset')\n",
    "OUTPUT_DIR = \"low_confidence_analysis\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "print(\"Loading model for inference...\")\n",
    "config = PeftConfig.from_pretrained(MODEL_PATH)\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.base_model_name_or_path, num_labels=3\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(base_model, MODEL_PATH)\n",
    "model.eval()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "def load_and_scan():\n",
    "    results = {0: [], 1: [], 2: []}\n",
    "    \n",
    "    paths = {\n",
    "        0: (DATASET_DIR / 'class1-human-written', ['01-arthur-conan-doyle', '02-pg-wodehouse', '03-mark-twain', '04-william-shakespeare'], 'extracted_paragraphs'),\n",
    "        1: (DATASET_DIR / 'class2-ai-written', ['ai-generated-paragraphs'], ''), \n",
    "        2: (DATASET_DIR / 'class3-ai-mimicry', ['01-arthur-conan-doyle', '02-pg-wodehouse', '03-mark-twain', '04-william-shakespeare'], '')\n",
    "    }\n",
    "\n",
    "    print(\"\\nScanning dataset for low-confidence samples...\")\n",
    "    \n",
    "    for label, (base_path, subfolders, suffix) in paths.items():\n",
    "        files = []\n",
    "        for sub in subfolders:\n",
    "            if suffix:\n",
    "                search_path = base_path / sub / suffix\n",
    "            else:\n",
    "                if sub == 'ai-generated-paragraphs': \n",
    "                    search_path = base_path / sub\n",
    "                else:\n",
    "                    search_path = base_path / sub\n",
    "            \n",
    "            files.extend(glob.glob(os.path.join(str(search_path), '*.txt')))\n",
    "\n",
    "        print(f\"Scanning Class {label} ({len(files)} files)...\")\n",
    "        \n",
    "        for file_path in tqdm(files):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    text = f.read().strip()\n",
    "                \n",
    "                if not text: continue\n",
    "\n",
    "                inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "                with torch.no_grad():\n",
    "                    logits = model(**inputs).logits\n",
    "                    probs = torch.softmax(logits, dim=1)[0]\n",
    "                \n",
    "                confidence = probs[label].item()\n",
    "                \n",
    "                results[label].append({\n",
    "                    'confidence': confidence,\n",
    "                    'text': text,\n",
    "                    'file': os.path.basename(file_path),\n",
    "                    'probs': probs.cpu().numpy()\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    return results\n",
    "\n",
    "data_map = load_and_scan()\n",
    "lowest_samples = {}\n",
    "\n",
    "print(\"\\n--- RESULTS: LOWEST CONFIDENCE SAMPLES ---\")\n",
    "\n",
    "file_names = {\n",
    "    0: \"low-confidence-class-1-human.txt\",\n",
    "    1: \"low-confidence-class-2-generic.txt\",\n",
    "    2: \"low-confidence-class-3-mimic.txt\"\n",
    "}\n",
    "\n",
    "for label in [0, 1, 2]:\n",
    "    sorted_samples = sorted(data_map[label], key=lambda x: x['confidence'])\n",
    "    \n",
    "    bottom_3 = sorted_samples[:3]\n",
    "    lowest_samples[label] = bottom_3\n",
    "    \n",
    "    out_file = os.path.join(OUTPUT_DIR, file_names[label])\n",
    "    with open(out_file, 'w', encoding='utf-8') as f:\n",
    "        print(f\"\\n[Class {label}] Lowest Confidence:\")\n",
    "        for i, sample in enumerate(bottom_3):\n",
    "            header = f\"Sample {i+1} | Conf: {sample['confidence']:.2%} | File: {sample['file']}\"\n",
    "            print(f\"  {header}\")\n",
    "            f.write(f\"{header}\\n\")\n",
    "            f.write(f\"{sample['text']}\\n\")\n",
    "            f.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(\"\\nRunning SHAP Analysis on these 9 samples...\")\n",
    "\n",
    "def predict_shap(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        scores = torch.softmax(logits, dim=1)\n",
    "    return scores.cpu().numpy()\n",
    "\n",
    "explainer = shap.Explainer(predict_shap, tokenizer)\n",
    "\n",
    "texts_to_explain = []\n",
    "labels_for_plot = []\n",
    "\n",
    "for label in [0, 1, 2]:\n",
    "    for sample in lowest_samples[label]:\n",
    "        texts_to_explain.append(sample['text'])\n",
    "        labels_for_plot.append(f\"Class_{label}_Conf_{sample['confidence']:.2f}\")\n",
    "\n",
    "shap_values = explainer(texts_to_explain)\n",
    "\n",
    "html_path = os.path.join(OUTPUT_DIR, \"low_confidence_shap_map.html\")\n",
    "with open(html_path, \"w\", encoding='utf-8') as f:\n",
    "    f.write(shap.plots.text(shap_values, display=False))\n",
    "\n",
    "print(f\"\\nDONE! \\n1. Text files saved in '{OUTPUT_DIR}'\\n2. SHAP visualization saved to '{html_path}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
