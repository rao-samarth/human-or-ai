{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b49b2567",
   "metadata": {},
   "source": [
    "This is an extension to the main task-1. It includes how information theoretic concepts (specifically perplexity) and geometric concepts (local intrinsic dimension) can be used to differentiate between AI and human-written text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa3e87b",
   "metadata": {},
   "source": [
    "# V. Information-Theoretic Signatures\n",
    "\n",
    "Information theory quantifies predictability. AI, is very predictable. Or it should be. That's what we're going to see here...  \n",
    "\n",
    "Before getting started on the specifics, [this blog](https://kuiper2000.github.io/chaos_and_predictability/week9/week9) explains the basics of information theory, and how it ties into predictability quite well. I enjoyed reading it.\n",
    "\n",
    "I also want to preface by saying that I am by no means an expert / know much about information theory. I tried to learn a bit for the purposes of this task, but my domain knowledge is limited to that. I also thank the Infosec class and TA's for hinting the basics of this to us, which led me down this rabbit hole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e80f1f",
   "metadata": {},
   "source": [
    "## Perplexity\n",
    "\n",
    "[This blog](https://medium.com/nlplanet/two-minutes-nlp-perplexity-explained-with-simple-probabilities-6cdc46884584) explains perplexity really nicely through a simple example.\n",
    "\n",
    "In general, it is a measure of how well a given sentence is predicted. Or, in the sense of the word itself, how **perplexed** a model is when reading text. Lower perplexity => less perplexed, higher perplexity => more perplexed.\n",
    "\n",
    "- Because AI generates text by selecting high-probability tokens, the resulting text has statistically low perplexity. It follows the \"path of least resistance.\" However, since our temperature is relatively high (set to 1), the perplexity may be higher than usual AI generated text.\n",
    "- Human writing - especially famous authors - is replete with choices. Creative metaphors, sudden topic shifts, and idiomatic expressions that statistically defy the model's predictive expectations.\n",
    "\n",
    "\n",
    "### The maths behind perplexity\n",
    "\n",
    "This section is inspired by [Fabio Chiusano's Medium post.](https://medium.com/nlplanet/two-minutes-nlp-perplexity-explained-with-simple-probabilities-6cdc46884584)\n",
    "\n",
    "A language model predicts text **one word at a time**.\n",
    "\n",
    "For a sentence like:\n",
    "\n",
    "> **\"a red fox.\"**\n",
    "\n",
    "the model assigns probabilities like:\n",
    "\n",
    "- P(\"a\")\n",
    "- P(\"red\" | \"a\")\n",
    "- P(\"fox\" | \"a red\")\n",
    "- P(\".\" | \"a red fox\")\n",
    "\n",
    "To get the probability of the **whole sentence**, we multiply:\n",
    "\n",
    "$$\n",
    "P(W) = P(w_1) \\times P(w_2|w_1) \\times \\dots \\times P(w_n|w_1,\\dots,w_{n-1})\n",
    "$$\n",
    "\n",
    "Example:\n",
    "\n",
    "$$\n",
    "P(\\text{\"a red fox.\"}) = 0.4 \\times 0.27 \\times 0.55 \\times 0.79 = 0.0469\n",
    "$$\n",
    "\n",
    "**Problem: longer sentences always get smaller probabilities**\n",
    "\n",
    "Multiplying many numbers **smaller than 1** makes the result very small.\n",
    "\n",
    "So:\n",
    "- Long sentences → tiny probabilities  \n",
    "- Short sentences → bigger probabilities  \n",
    "\n",
    "This makes comparisons **unfair**.\n",
    "\n",
    "---\n",
    "\n",
    "To remove the effect of sentence length, we **average** the probabilities using the **geometric mean**.\n",
    "\n",
    "For a sentence with `n` words:\n",
    "\n",
    "$$\n",
    "P_{\\text{norm}}(W) = P(W)^{1/n}\n",
    "$$\n",
    "\n",
    "Example:\n",
    "\n",
    "$$\n",
    "P_{\\text{norm}}(\\text{\"a red fox.\"}) = 0.0469^{1/4} = 0.465\n",
    "$$\n",
    "\n",
    "This means that on average, the model assigns about **46.5% confidence per word**.\n",
    "\n",
    "---\n",
    "\n",
    "Perplexity is just the **inverse** of this normalized probability:\n",
    "\n",
    "$$\n",
    "\\text{Perplexity}(W) = \\frac{1}{P_{\\text{norm}}(W)}\n",
    "$$\n",
    "\n",
    "or  \n",
    "\n",
    "$$\n",
    "\\text{Perplexity}(W) = \\left(\\frac{1}{P(W)}\\right)^{1/n}\n",
    "$$\n",
    "\n",
    "Example:\n",
    "\n",
    "$$\n",
    "\\text{PP} = \\frac{1}{0.465} \\approx 2.15\n",
    "$$\n",
    "\n",
    "### Interpretation:\n",
    "- Perplexity ≈ 2 => the model feels like it's choosing between **2 reasonable words** at each step\n",
    "\n",
    "So we can see that a bad model has high perplexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22aa1c7",
   "metadata": {},
   "source": [
    "### How we are calculating the Perplexity in code\n",
    "\n",
    "Perplexity calculation happens in 4 main steps:\n",
    "1. Tokenization: The text is converted into token-id's which GPT2 understands.\n",
    "2. Teacher Forcing: The key is labels=input_ids. This basically tells GPT2:\n",
    "- here is your input sequence\n",
    "- now predict each subsequent token\n",
    "- calculate loss\n",
    "\n",
    "3. Cross-Entropy Loss: GPT2 calculates its loss (how wrong each prediction was).\n",
    "- For each prediction, it predicts a probability distribution of all possible next tokens.\n",
    "- The loss is measured as the gap between predicted probability and the actual token.\n",
    "\n",
    "4. Next, we want to convert loss to probability. `perplexity = exp(loss)`\n",
    "\n",
    "\n",
    "**IMPORTANT NOTE:** Perplexity is also affected by temperature. As temperature increases, the AI becomes more non-deterministic, and so perplexity increases significantly as well. We use a temperature of 1.0 for creation of class 2 and class 3. This will result in higher than expected, however, it will still mostly be lower than that of humans. Generally, AI achieves human levels of perplexity only at temperatures >1.5. [Source - Peeperkorn et al., 2024](https://arxiv.org/html/2405.00492v1).\n",
    "\n",
    "# IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad83a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "✓ Google Drive mounted successfully\n",
      "\n",
      "Using dataset directory: /content/drive/MyDrive/precog-my-dataset/dataset\n",
      "✓ Dataset directory found!\n",
      "  Contains 5 subdirectories\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Check if running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Google Colab - attempting to mount Drive...\")\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        # Adjust this path to where you stored the dataset in Google Drive\n",
    "        DATASET_DIR = Path('/content/drive/MyDrive/precog-my-dataset/dataset')\n",
    "        print(f\"✓ Google Drive mounted successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to mount Google Drive: {e}\")\n",
    "        print(\"Falling back to local path...\")\n",
    "        DATASET_DIR = Path('../dataset')\n",
    "else:\n",
    "    print(\"Running locally (not in Colab)\")\n",
    "    DATASET_DIR = Path('../dataset')\n",
    "\n",
    "print(f\"\\nUsing dataset directory: {DATASET_DIR.resolve()}\")\n",
    "\n",
    "# Verify the path exists\n",
    "if DATASET_DIR.exists():\n",
    "    print(f\"✓ Dataset directory found!\")\n",
    "    # Count subdirectories\n",
    "    subdirs = [d for d in DATASET_DIR.iterdir() if d.is_dir()]\n",
    "    print(f\"  Contains {len(subdirs)} subdirectories\")\n",
    "else:\n",
    "    print(f\"✗ Dataset directory NOT found at {DATASET_DIR.resolve()}\")\n",
    "    print(f\"  Please ensure your dataset folder is in the correct location.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e79fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 model and tokenizer...\n",
      "(This may take a bit if downloading for the first time)\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 148/148 [00:00<00:00, 818.37it/s, Materializing param=transformer.wte.weight]             \n",
      "GPT2LMHeadModel LOAD REPORT from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully!\n",
      "\n",
      "======================================================================\n",
      "SETTING UP PATHS\n",
      "======================================================================\n",
      "\n",
      "Verifying paths...\n",
      "\n",
      "Class 1:\n",
      "  ✓ ../dataset/class1-human-written/01-arthur-conan-doyle/extracted_paragraphs\n",
      "  ✓ ../dataset/class1-human-written/02-pg-wodehouse/extracted_paragraphs\n",
      "  ✓ ../dataset/class1-human-written/03-mark-twain/extracted_paragraphs\n",
      "  ✓ ../dataset/class1-human-written/04-william-shakespeare/extracted_paragraphs\n",
      "\n",
      "Class 2:\n",
      "  ✓ ../dataset/class2-ai-written/ai-generated-paragraphs\n",
      "\n",
      "Class 3:\n",
      "  ✓ ../dataset/class3-ai-mimicry/01-arthur-conan-doyle\n",
      "  ✓ ../dataset/class3-ai-mimicry/02-pg-wodehouse\n",
      "  ✓ ../dataset/class3-ai-mimicry/03-mark-twain\n",
      "  ✓ ../dataset/class3-ai-mimicry/04-william-shakespeare\n",
      "\n",
      "======================================================================\n",
      "CALCULATING PERPLEXITIES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Processing Class 1 (Human)\n",
      "======================================================================\n",
      "Searching for text files...\n",
      "  Found 500 files in extracted_paragraphs\n",
      "  Found 500 files in extracted_paragraphs\n",
      "  Found 480 files in extracted_paragraphs\n",
      "  Found 480 files in extracted_paragraphs\n",
      "✓ Total: 1960 text files\n",
      "\n",
      "Reading 1960 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 1960/1960 [00:00<00:00, 8209.50file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully read 1960 valid text files\n",
      "\n",
      "Calculating perplexities for 1960 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexities:   0%|          | 0/1960 [00:00<?, ?text/s]`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "Calculating perplexities: 100%|██████████| 1960/1960 [07:56<00:00,  4.12text/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results for Class 1 (Human):\n",
      "  Mean Perplexity:   57.48\n",
      "  Median Perplexity: 49.98\n",
      "  Std Dev:           28.97\n",
      "  Min:               5.22\n",
      "  Max:               241.31\n",
      "  Sample size:       1960\n",
      "\n",
      "======================================================================\n",
      "Processing Class 2 (AI)\n",
      "======================================================================\n",
      "Searching for text files...\n",
      "  Found 988 files in ai-generated-paragraphs\n",
      "✓ Total: 988 text files\n",
      "\n",
      "Reading 988 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 988/988 [00:00<00:00, 7663.18file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully read 988 valid text files\n",
      "\n",
      "Calculating perplexities for 988 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexities: 100%|██████████| 988/988 [03:43<00:00,  4.41text/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results for Class 2 (AI):\n",
      "  Mean Perplexity:   48.63\n",
      "  Median Perplexity: 47.40\n",
      "  Std Dev:           13.22\n",
      "  Min:               18.68\n",
      "  Max:               110.91\n",
      "  Sample size:       988\n",
      "\n",
      "======================================================================\n",
      "Processing Class 3 (AI Mimicry)\n",
      "======================================================================\n",
      "Searching for text files...\n",
      "  Found 250 files in 01-arthur-conan-doyle\n",
      "  Found 250 files in 02-pg-wodehouse\n",
      "  Found 237 files in 03-mark-twain\n",
      "  Found 236 files in 04-william-shakespeare\n",
      "✓ Total: 973 text files\n",
      "\n",
      "Reading 973 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading files: 100%|██████████| 973/973 [00:00<00:00, 7411.52file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully read 972 valid text files\n",
      "\n",
      "Calculating perplexities for 972 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexities: 100%|██████████| 972/972 [03:58<00:00,  4.08text/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results for Class 3 (AI Mimicry):\n",
      "  Mean Perplexity:   64.96\n",
      "  Median Perplexity: 61.70\n",
      "  Std Dev:           19.65\n",
      "  Min:               30.28\n",
      "  Max:               347.20\n",
      "  Sample size:       972\n",
      "\n",
      "======================================================================\n",
      "PERPLEXITY SUMMARY\n",
      "======================================================================\n",
      "Class                     Mean         Median       Std          Files     \n",
      "----------------------------------------------------------------------\n",
      "Class 1 (Human)           57.48        49.98        28.97        1960      \n",
      "Class 2 (AI)              48.63        47.40        13.22        988       \n",
      "Class 3 (AI Mimicry)      64.96        61.70        19.65        972       \n",
      "======================================================================\n",
      "\n",
      "INTERPRETATION:\n",
      "----------------------------------------------------------------------\n",
      "Lower perplexity = More predictable text (typical of AI)\n",
      "Higher perplexity = Less predictable text (typical of humans)\n",
      "\n",
      "Expected pattern:\n",
      "  Class 2 (AI) < Class 3 (AI Mimicry) < Class 1 (Human)\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import numpy as np\n",
    "import statistics\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DATASET_DIR = Path('../dataset')\n",
    "\n",
    "print(\"Loading GPT-2 model and tokenizer...\")\n",
    "print(\"(This may take a bit if downloading for the first time)\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "try:\n",
    "    # Load model and tokenizer\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "    gpt2_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "    \n",
    "    # Set padding token (GPT-2 doesn't have one by default)\n",
    "    gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "    \n",
    "    model.eval()\n",
    "    print(\"✓ Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading model: {e}\")\n",
    "    print(\"\\nTip: If you're getting timeout errors, try running:\")\n",
    "    print(\"  export HF_HUB_DOWNLOAD_TIMEOUT=300\")\n",
    "    print(\"in your terminal before running this cell, or download manually.\")\n",
    "    raise\n",
    "\n",
    "def calculate_perplexity_single(text):\n",
    "    \"\"\"Calculate perplexity for a single text\"\"\"\n",
    "    try:\n",
    "        # Tokenize with truncation\n",
    "        encodings = gpt2_tokenizer(\n",
    "            text, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            max_length=1024\n",
    "        )\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        \n",
    "        # Calculate loss\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "            perplexity = torch.exp(loss).item()\n",
    "        \n",
    "        return perplexity\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating perplexity: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_perplexities_for_texts(texts, batch_size=1):\n",
    "    \"\"\"Calculate perplexity for multiple texts with progress bar\"\"\"\n",
    "    perplexities = []\n",
    "    \n",
    "    for text in tqdm(texts, desc=\"Calculating perplexities\", unit=\"text\"):\n",
    "        ppl = calculate_perplexity_single(text)\n",
    "        if ppl is not None:\n",
    "            perplexities.append(ppl)\n",
    "    \n",
    "    return perplexities\n",
    "\n",
    "def read_file_safe(file_path):\n",
    "    \"\"\"Safely read a file and return its content\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read().strip()\n",
    "        # Only return if text is not empty and has reasonable length\n",
    "        if text and len(text) > 10:\n",
    "            return text\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_text_files_from_paths(path_list):\n",
    "    \"\"\"Get all .txt files from a list of directory paths\"\"\"\n",
    "    txt_files = []\n",
    "    for path in path_list:\n",
    "        if path.exists():\n",
    "            files = list(path.glob('*.txt'))\n",
    "            txt_files.extend(files)\n",
    "            print(f\"  Found {len(files)} files in {path.name}\")\n",
    "        else:\n",
    "            print(f\"  ✗ Warning: Path does not exist: {path}\")\n",
    "    return txt_files\n",
    "\n",
    "# Define paths matching the structure from task-1.ipynb\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SETTING UP PATHS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Class 1: Human-written\n",
    "class1_paths = [\n",
    "    DATASET_DIR / 'class1-human-written' / '01-arthur-conan-doyle' / 'extracted_paragraphs',\n",
    "    DATASET_DIR / 'class1-human-written' / '02-pg-wodehouse' / 'extracted_paragraphs',\n",
    "    DATASET_DIR / 'class1-human-written' / '03-mark-twain' / 'extracted_paragraphs',\n",
    "    DATASET_DIR / 'class1-human-written' / '04-william-shakespeare' / 'extracted_paragraphs'\n",
    "]\n",
    "\n",
    "# Class 2: AI-written\n",
    "class2_paths = [\n",
    "    DATASET_DIR / 'class2-ai-written' / 'ai-generated-paragraphs'\n",
    "]\n",
    "\n",
    "# Class 3: AI-mimicry\n",
    "class3_paths = [\n",
    "    DATASET_DIR / 'class3-ai-mimicry' / '01-arthur-conan-doyle',\n",
    "    DATASET_DIR / 'class3-ai-mimicry' / '02-pg-wodehouse',\n",
    "    DATASET_DIR / 'class3-ai-mimicry' / '03-mark-twain',\n",
    "    DATASET_DIR / 'class3-ai-mimicry' / '04-william-shakespeare'\n",
    "]\n",
    "\n",
    "# Verify all paths exist\n",
    "print(\"\\nVerifying paths...\")\n",
    "all_paths_valid = True\n",
    "for name, paths in [(\"Class 1\", class1_paths), (\"Class 2\", class2_paths), (\"Class 3\", class3_paths)]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    for p in paths:\n",
    "        status = \"✓\" if p.exists() else \"✗\"\n",
    "        print(f\"  {status} {p}\")\n",
    "        if not p.exists():\n",
    "            all_paths_valid = False\n",
    "\n",
    "if not all_paths_valid:\n",
    "    print(\"\\n⚠ Warning: Some paths don't exist!\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CALCULATING PERPLEXITIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "perplexity_results = {}\n",
    "\n",
    "for class_name, class_paths in [(\"Class 1 (Human)\", class1_paths), \n",
    "                                 (\"Class 2 (AI)\", class2_paths), \n",
    "                                 (\"Class 3 (AI Mimicry)\", class3_paths)]:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing {class_name}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    # Get all text files\n",
    "    print(\"Searching for text files...\")\n",
    "    text_files = get_text_files_from_paths(class_paths)\n",
    "    print(f\"✓ Total: {len(text_files)} text files\")\n",
    "    \n",
    "    if len(text_files) == 0:\n",
    "        print(f\"✗ No files found. Skipping {class_name}...\")\n",
    "        continue\n",
    "    \n",
    "    # Read all files\n",
    "    print(f\"\\nReading {len(text_files)} files...\")\n",
    "    all_texts = []\n",
    "    for file_path in tqdm(text_files, desc=\"Reading files\", unit=\"file\"):\n",
    "        text = read_file_safe(file_path)\n",
    "        if text:\n",
    "            all_texts.append(text)\n",
    "    \n",
    "    print(f\"✓ Successfully read {len(all_texts)} valid text files\")\n",
    "    \n",
    "    if not all_texts:\n",
    "        print(f\"✗ No valid texts found. Skipping {class_name}...\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate perplexities\n",
    "    print(f\"\\nCalculating perplexities for {len(all_texts)} texts...\")\n",
    "    perplexities = calculate_perplexities_for_texts(all_texts)\n",
    "    \n",
    "    # Filter out None values\n",
    "    perplexities = [p for p in perplexities if p is not None and not np.isnan(p) and not np.isinf(p)]\n",
    "    \n",
    "    if perplexities:\n",
    "        mean_perplexity = statistics.mean(perplexities)\n",
    "        median_perplexity = statistics.median(perplexities)\n",
    "        std_perplexity = statistics.stdev(perplexities) if len(perplexities) > 1 else 0\n",
    "        min_perplexity = min(perplexities)\n",
    "        max_perplexity = max(perplexities)\n",
    "        \n",
    "        perplexity_results[class_name] = {\n",
    "            'mean': mean_perplexity,\n",
    "            'median': median_perplexity,\n",
    "            'std': std_perplexity,\n",
    "            'min': min_perplexity,\n",
    "            'max': max_perplexity,\n",
    "            'count': len(perplexities)\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n✓ Results for {class_name}:\")\n",
    "        print(f\"  Mean Perplexity:   {mean_perplexity:.2f}\")\n",
    "        print(f\"  Median Perplexity: {median_perplexity:.2f}\")\n",
    "        print(f\"  Std Dev:           {std_perplexity:.2f}\")\n",
    "        print(f\"  Min:               {min_perplexity:.2f}\")\n",
    "        print(f\"  Max:               {max_perplexity:.2f}\")\n",
    "        print(f\"  Sample size:       {len(perplexities)}\")\n",
    "    else:\n",
    "        print(f\"✗ No valid perplexity values calculated for {class_name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERPLEXITY SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Class':<25} {'Mean':<12} {'Median':<12} {'Std':<12} {'Files':<10}\")\n",
    "print(\"-\"*70)\n",
    "for class_name, stats in perplexity_results.items():\n",
    "    print(f\"{class_name:<25} {stats['mean']:<12.2f} {stats['median']:<12.2f} {stats['std']:<12.2f} {stats['count']:<10}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Interpretation\n",
    "if perplexity_results:\n",
    "    print(\"\\nINTERPRETATION:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(\"Lower perplexity = More predictable text (typical of AI)\")\n",
    "    print(\"Higher perplexity = Less predictable text (typical of humans)\")\n",
    "    print(\"\\nExpected pattern:\")\n",
    "    print(\"  Class 2 (AI) < Class 3 (AI Mimicry) < Class 1 (Human)\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8847f53d",
   "metadata": {},
   "source": [
    "## Adding Perplexity to math.csv\n",
    "\n",
    "Now we'll add the perplexity values to the existing math.csv file so they can be used for analysis alongside other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63b95b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../task-1/math.csv...\n",
      "✓ Loaded 3921 rows\n",
      "Columns: ['class', 'text_file_name', 'author', 'word_count', 'ttr', 'hapax_ratio', 'zipf_alpha', 'zipf_mape', 'avg_parse_depth', 'adj_noun_ratio', 'noun_verb_ratio', 'adverb_verb_ratio', 'em_dash_freq', 'semicolon_freq', 'colon_freq', 'exclamation_freq', 'double_quote_freq', 'flesch_kincaid_grade']\n",
      "\n",
      "✓ Adding new 'perplexity' column\n",
      "\n",
      "Calculating perplexity for all texts...\n",
      "This may take several minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 3921/3921 [13:33<00:00,  4.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Perplexity calculation complete!\n",
      "  Successfully calculated: 3171\n",
      "  Failed/Missing: 750\n",
      "\n",
      "Saving updated CSV to ../task-1/math.csv...\n",
      "Saved successfully!\n",
      "\n",
      "PERPLEXITY STATISTICS BY CLASS\n",
      "\n",
      "Class 1: Human-written:\n",
      "  Count:  1460\n",
      "  Mean:   58.46\n",
      "  Median: 49.27\n",
      "  Std:    31.96\n",
      "  Min:    5.22\n",
      "  Max:    241.31\n",
      "\n",
      "Class 2: AI-written:\n",
      "  Count:  988\n",
      "  Mean:   48.63\n",
      "  Median: 47.40\n",
      "  Std:    13.22\n",
      "  Min:    18.68\n",
      "  Max:    110.91\n",
      "\n",
      "Class 3: AI-mimicry:\n",
      "  Count:  723\n",
      "  Mean:   64.21\n",
      "  Median: 60.57\n",
      "  Std:    18.47\n",
      "  Min:    30.28\n",
      "  Max:    155.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Load the existing math.csv\n",
    "csv_path = Path('../task-1/math.csv')\n",
    "print(f\"Loading {csv_path}...\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"✓ Loaded {len(df)} rows\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Check if perplexity column already exists\n",
    "if 'perplexity' in df.columns:\n",
    "    print(\"\\n⚠ Warning: 'perplexity' column already exists!\")\n",
    "    print(\"Overwriting existing values...\")\n",
    "else:\n",
    "    print(\"\\n✓ Adding new 'perplexity' column\")\n",
    "\n",
    "# Create a mapping of class names to directory paths\n",
    "def get_file_path(row):\n",
    "    \"\"\"Construct the full file path from the row data\"\"\"\n",
    "    class_name = row['class']\n",
    "    filename = row['text_file_name']\n",
    "    author = row['author']\n",
    "    \n",
    "    # Map authors to directory names\n",
    "    author_dirs = {\n",
    "        'Arthur Conan Doyle': '01-arthur-conan-doyle',\n",
    "        'P. G. Wodehouse': '02-pg-wodehouse',\n",
    "        'Mark Twain': '03-mark-twain',\n",
    "        'William Shakespeare': '04-william-shakespeare'\n",
    "    }\n",
    "    \n",
    "    if class_name == 'Class 1: Human-written':\n",
    "        author_dir = author_dirs.get(author)\n",
    "        if author_dir:\n",
    "            return DATASET_DIR / 'class1-human-written' / author_dir / 'extracted_paragraphs' / filename\n",
    "    elif class_name == 'Class 2: AI-written':\n",
    "        return DATASET_DIR / 'class2-ai-written' / 'ai-generated-paragraphs' / filename\n",
    "    elif class_name == 'Class 3: AI-mimicry':\n",
    "        author_dir = author_dirs.get(author)\n",
    "        if author_dir:\n",
    "            return DATASET_DIR / 'class3-ai-mimicry' / author_dir / filename\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Calculate perplexity for each text\n",
    "print(\"\\nCalculating perplexity for all texts...\")\n",
    "print(\"This may take several minutes...\")\n",
    "\n",
    "perplexities = []\n",
    "failed_count = 0\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing files\"):\n",
    "    file_path = get_file_path(row)\n",
    "    \n",
    "    if file_path and file_path.exists():\n",
    "        text = read_file_safe(file_path)\n",
    "        if text:\n",
    "            ppl = calculate_perplexity_single(text)\n",
    "            if ppl is not None and not np.isnan(ppl) and not np.isinf(ppl):\n",
    "                perplexities.append(ppl)\n",
    "            else:\n",
    "                perplexities.append(None)\n",
    "                failed_count += 1\n",
    "        else:\n",
    "            perplexities.append(None)\n",
    "            failed_count += 1\n",
    "    else:\n",
    "        perplexities.append(None)\n",
    "        failed_count += 1\n",
    "\n",
    "# Add perplexity column to dataframe\n",
    "df['perplexity'] = perplexities\n",
    "\n",
    "print(f\"\\n✓ Perplexity calculation complete!\")\n",
    "print(f\"  Successfully calculated: {len([p for p in perplexities if p is not None])}\")\n",
    "print(f\"  Failed/Missing: {failed_count}\")\n",
    "\n",
    "# Save updated CSV\n",
    "print(f\"\\nSaving updated CSV to {csv_path}...\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(\"Saved successfully!\")\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"\\nPERPLEXITY STATISTICS BY CLASS\")\n",
    "\n",
    "for class_name in df['class'].unique():\n",
    "    class_data = df[df['class'] == class_name]['perplexity'].dropna()\n",
    "    if len(class_data) > 0:\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"  Count:  {len(class_data)}\")\n",
    "        print(f\"  Mean:   {class_data.mean():.2f}\")\n",
    "        print(f\"  Median: {class_data.median():.2f}\")\n",
    "        print(f\"  Std:    {class_data.std():.2f}\")\n",
    "        print(f\"  Min:    {class_data.min():.2f}\")\n",
    "        print(f\"  Max:    {class_data.max():.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
